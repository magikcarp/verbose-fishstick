#!/usr/bin/env python
# -*- coding: utf-8 -*-

""" Establishes architecture for UNet model. """

import torch
import torch.nn as nn

from collections.abc import Callable


class UNet(nn.Module):
    """ 
    UNet network for convolving image data.

    Attributes:
        down_conv (nn.ModuleList[DoubleConvolution]): series of double 
            convolutions in the image encoding arm. 
        down_sample (nn.ModuleList[DownSample]): pooling layers with kernel size
            of 2 x 2 and a stride of 2. 
        middle_conv (DoubleConvolution): the bottom convolution of the U-Net.
        up_conv (nn.ModuleList[DoubleConvolution]): series of double 
            convolutions in the image decoding arm. 
        up_sample (nn.ModuleList[UpSample]): series of deconvolutions. 
        concat (nn.ModuleList[Concat]): performs concatenations between same 
            sized layers in the U-Net architecture. 
        last_conv (DoubleConvolution): final convolution that outputs number of 
            out channels. 
        sigmoid (nn.Sigmoid): performs normalization of logits to [0, 1]. 

    The number of kernels can be customized if desired. Example network sizes:
        - UNet : [64, 128, 256, 512, 1024]
        - SmallUNet : [32, 64, 128, 256, 512]
        - MiniUNet : [16, 32, 64, 128, 256]
        - TinyUNet : [8, 16, 32, 64, 128]
        - DeepUNet : [8, 16, 32, 64, 128, 256, 512, 1024]
            - Should only be used with very large images due to down sampling
            (image demnsions are halved after each layer of double convolution)
    """
    def __init__(self,
                 in_channels: int,
                 out_channels: int,
                 n_layer_kernels: list[int]=[64, 128, 256, 512, 1024]):
        """ 
        Creates a UNet model with desired number of in and out channels.

        Args:
            in_channels (int): number of channels in the original image.
            out_channels (int): number of desired output channels.
            n_layer_kernels (list[int]): the number of kernels in each layer of
                the network. It is highly recommended that values are sequential
                powers of 2. Default is [64, 128, 256, 512, 1024].
        """
        super().__init__()
        n_kern = n_layer_kernels.copy() # in case input shouldn't mutate
        n_kern.insert(0, in_channels)
        down_kerns = [(n_kern[i], n_kern[i+1]) for i in range(len(n_kern)-2)]
        up_kerns = [(n_kern[i], n_kern[i-1]) for i in range(len(n_kern)-1, 1, -1)]
        n_steps = len(down_kerns)

        # Encoding arm
        self.down_conv = nn.ModuleList(
            [DoubleConvolution(i, o) for i, o in down_kerns]
        )
        self.down_sample = nn.ModuleList([DownSample() for _ in range(n_steps)])

        # Bottom of the U
        self.middle_conv = DoubleConvolution(
            n_kern[len(n_kern)-2], n_kern[len(n_kern)-1]
        )

        # Decoding arm
        self.up_conv = nn.ModuleList(
            [DoubleConvolution(i, o) for i, o in up_kerns]
        )
        self.up_sample = nn.ModuleList(
            [UpSample(i, o) for i, o in up_kerns]
        )
        self.concat = nn.ModuleList(Concat() for _ in range(n_steps))

        # Output
        self.last_conv = nn.Conv2d(n_kern[1], out_channels, kernel_size=1)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x: torch.Tensor) -> torch.Tensor:
        """ 
        Forward pass of data x through UNet architecture.

        The tensor x is passes through each segment of the encoding and
        decoding portion of the network before a final 1x1 convolutional layer
        and sigmoidal activation returning a shape of [1 x 512 x 512]. A mask
        can be generated by thresholding the output at a desired value.

        Args:
            x (torch.Tensor): BATCH_SIZE x 1 x 512 x 512 grayscale image.

        Returns:
            torch.Tensor: mask of the provided image.
        """
        through_pass = []
        for i in range(len(self.down_conv)):
            x = self.down_conv[i](x)
            through_pass.append(x)
            x = self.down_sample[i](x)
        x = self.middle_conv(x)
        for i in range(len(self.up_conv)):
            x = self.up_sample[i](x)
            x = self.concat[i](x, through_pass.pop())
            x = self.up_conv[i](x)
        x = self.last_conv(x)
        x = self.sigmoid(x)
        return x
    
    def train_model(
            self,
            train_loader: torch.utils.data.DataLoader,
            n_epochs: int,
            optimizer: torch.optim.Optimizer,
            loss_fn: Callable,
            verbose: bool=False,
            report_iter: int=25,
        ) -> None:
        """ 
        Train the UNet model using the training data. 

        Args:
            train_loader (torch.utils.data.DataLoader): training data loader
            n_epochs (int): the number of training rounds through the dataset
            optimizer (torch.optim.Optimizer): optimizing function
            loss_fn (Callable): function to calculate loss
            verbose (bool): Indicates if function prints. Default is false.
            report_iter (int): Prints loss every nth batch. Default is 25.

        Returns:
            None
        """
        self.train() # set the model to training mode
        for e in range(n_epochs):
            if verbose:
                print(f"EPOCH {e+1}")
            for i, batch in enumerate(train_loader):
                images = batch["image"]
                masks = batch["mask"]

                optimizer.zero_grad()
                y_pred = self(images)
                loss = loss_fn(y_pred, masks)
                loss.backward()
                optimizer.step()

                if verbose and i % report_iter == (report_iter - 1):
                    print(f" - batch {i+1} loss: {loss}")
        return None


class DoubleConvolution(nn.Module):
    """ 
    Neural network layer that performs two convolutions with a 3x3 kernel,
    each followed by ReLU activation. 
    """
    def __init__(self, in_channels: int, out_channels: int):
        super().__init__()
        self.c1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1)
        self.a1 = nn.ReLU()
        self.c2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1)
        self.a2 = nn.ReLU()
        
    def forward(self, x: torch.Tensor):
        """ Forward pass through a double convolution. """
        x = self.c1(x)
        x = self.a1(x)
        x = self.c2(x)
        x = self.a2(x)
        return x


class DownSample(nn.Module):
    """ Max pool with a kernel size and stride of 2. """
    def __init__(self):
        super().__init__()
        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)

    def forward(self, x: torch.Tensor):
        """ Forward pass through 2D pooling layer. """
        return self.pool(x)


class Concat(nn.Module):
    """ 
    Concatenates two tensors of similar shape along channel dimsension.

    Concat assumes the incoming data is of the shape [B x C x W x H] where B
    is the batches, C is the number of channels, and W and H are the width and
    height of the image. 
    """
    def forward(self, x: torch.Tensor, contracting_x: torch.Tensor):
        """ Forward pass through concatenation of two tensors. """
        return torch.concat([x, contracting_x], dim=1)


class UpSample(nn.Module):
    """ Performs upsampling of data with a kernel size and stride of 2. """
    def __init__(self, in_channels: int, out_channels: int):
        super().__init__()
        self.up = nn.ConvTranspose2d(in_channels, out_channels, kernel_size=2, stride=2)

    def forward(self, x: torch.Tensor):
        """ Forward pass through upsampling process. """
        return self.up(x)


def seed_unet_kernels(first: int, n_layers: int) -> list[int]:
    """ 
    Constructs list of number of kernels in layer of convolutions.

    The value `first` indicates the first value in the list and subsequent
    values are the first value multiplied by a power of 2. 

    Args:
        first (int): the first value in list of kernels for initial convolution
        n_layers (int): the number of desired layers in the UNet

    Returns:
        list[int] 
    """
    return [first * (2**i) for i in range(n_layers)]
